{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from transformer_type.model import TransAm\n",
    "from transformer_type.dataset import get_data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)\n",
    "\n",
    "if torch.cuda.is_available(): device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available(): device = torch.device(\"mps\")\n",
    "else: device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_window, output_window, batch_size, epochs, feature_size, d_ff, num_layers, lr, dropout\n",
    "params = [[120, 1, 32, 300, 128, 128, 2, 1e-3, 0.1],\n",
    "          [120, 1, 32, 300, 128, 64, 1, 1e-3, 0.1],\n",
    "          [120, 1, 32, 300, 128, 512, 2, 1e-3, 0.1],\n",
    "          [120, 1, 32, 300, 128, 256, 2, 1e-3, 0.1],\n",
    "          [120, 1, 32, 300, 256, 64, 1, 1e-3, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"\"\n",
    "type_list = ['A', 'B', 'C', 'D', 'E', 'G', 'H', 'I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "val_data_list = []\n",
    "\n",
    "for type_name in type_list:\n",
    "    train_data, val_data, scaler = get_data(type_name, params[0], params[1])\n",
    "    train_data = train_data.to(device)\n",
    "    val_data = val_data.to(device)\n",
    "    train_data_list.append((train_data, type_name, scaler))\n",
    "    val_data_list.append((val_data, type_name, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {t : TransAm(*params).load_state_dict(torch.load(MODEL_PATH + f\"{t}_.pt\")) for t in type_list}\n",
    "cur_values = {}\n",
    "predictions = {}\n",
    "true_values = {}\n",
    "input_window, output_window = params[:2]\n",
    "\n",
    "for val_data, t, scaler in val_data_list:\n",
    "    model = models[t]\n",
    "    model.eval()\n",
    "    cur_values[t] = {}\n",
    "    predictions[t] = []\n",
    "    true_values[t] = []\n",
    "    for i in range(params[0], len(val_data) - 180):\n",
    "        _, data, scaler = val_data[i]\n",
    "        cur_values[t].append(data[-1])\n",
    "        for _ in range(180):\n",
    "            input = torch.clone(data[-input_window:])\n",
    "            input[-output_window:] = 0     \n",
    "            output = model(data[-input_window:])                        \n",
    "            data = torch.cat((data, output[-1:]))\n",
    "        predictions[t].append(output.item())\n",
    "        true_values[t].append(val_data[i + 180][1][-1])   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
